(window.webpackJsonp=window.webpackJsonp||[]).push([[79],{402:function(t,a,_){"use strict";_.r(a);var r=_(4),v=Object(r.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"gpt-4o使用详细教程-免费向所有用户提供gpt-4级别的ai-可以实时对音频、视觉和文本进行推理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#gpt-4o使用详细教程-免费向所有用户提供gpt-4级别的ai-可以实时对音频、视觉和文本进行推理"}},[t._v("#")]),t._v(" GPT-4o使用详细教程，免费向所有用户提供GPT-4级别的AI,可以实时对音频、视觉和文本进行推理")]),t._v(" "),a("p",[t._v("chatgpt 2024 Spring推出 GPT-4o，这是chatgpt的新旗舰模型，可以实时对音频、视觉和文本进行推理。")]),t._v(" "),a("p",[t._v("PS：如果想成为GPT-4o付费用户点击: "),a("a",{attrs:{href:"https://2233.ai/i/GPT310",target:"_blank",rel:"noopener noreferrer"}},[t._v("WildCard不开卡GPT4随心用"),a("OutboundLink")],1),t._v("  邀请码 "),a("strong",[t._v("GPT310")]),t._v("，直接免 2 美元的开卡费，虚拟卡开好之后，用支付宝充值进行ChatGpt升级，或者不开卡，直接使用chatgpt"),a("a",{attrs:{href:"https://2233.ai/i/GPT310",target:"_blank",rel:"noopener noreferrer"}},[t._v("ChatGPT随心用"),a("OutboundLink")],1),t._v("，只需手机号注册就能使用，等其他海外订阅服务。")]),t._v(" "),a("p",[t._v("GPT-4o（“o”代表“omni”）是迈向更自然的人机交互的一步——它接受文本、音频和图像的任意组合作为输入，并生成文本、音频和图像的任意组合输出。它可以在短至 232 毫秒的时间内响应音频输入，平均为 320 毫秒，与人类的响应时间相似在一次谈话中。")]),t._v(" "),a("p",[t._v("它在英语文本和代码上的性能与 GPT-4 Turbo 的性能相匹配，在非英语文本上的性能显著提高，同时 API 的速度也更快，成本降低了 50%。与现有模型相比，GPT-4o 在视觉和音频理解方面尤其出色。")]),t._v(" "),a("h2",{attrs:{id:"模型能力"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#模型能力"}},[t._v("#")]),t._v(" 模型能力")]),t._v(" "),a("p",[t._v("在 GPT-4o 之前，您可以使用语音模式与 ChatGPT 对话，平均延迟为 2.8 秒 (GPT-3.5) 和 5.4 秒 (GPT-4)。为了实现这一目标，语音模式是由三个独立模型组成的管道：一个简单模型将音频转录为文本，GPT-3.5 或 GPT-4 接收文本并输出文本，第三个简单模型将该文本转换回音频。这个过程意味着主要智能来源GPT-4丢失了大量信息——它无法直接观察音调、多个说话者或背景噪音，也无法输出笑声、歌唱或表达情感。")]),t._v(" "),a("p",[t._v("借助 GPT-4o，chatgpt跨文本、视觉和音频端到端地训练了一个新模型，这意味着所有输入和输出都由同一神经网络处理。由于 GPT-4o 是第一个结合所有这些模式的模型，因此chatgpt仍然只是浅尝辄止地探索该模型的功能及其局限性。")]),t._v(" "),a("h2",{attrs:{id:"模型评估"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#模型评估"}},[t._v("#")]),t._v(" 模型评估")]),t._v(" "),a("p",[t._v("根据传统基准测试，GPT-4o 在文本、推理和编码智能方面实现了 GPT-4 Turbo 级别的性能，同时在多语言、音频和视觉功能上设置了新的高水位线。")]),t._v(" "),a("p",[a("strong",[t._v("文本评价：")]),t._v(" GPT-4o 在 0-shot COT MMLU（常识问题）上创下了 88.7% 的新高分。此外，在传统的5-shot no-CoT MMLU上，GPT-4o创下了87.2%的新高分")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://hlplch.aliyuntm.com/chatgpt/5149.png",alt:""}})]),t._v(" "),a("p",[a("strong",[t._v("音频 ASR 性能：")]),t._v("  GPT-4o 比 Whisper-v3 显著提高了所有语言的语音识别性能，特别是对于资源匮乏的语言。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://hlplch.aliyuntm.com/chatgpt/5150.png",alt:""}})]),t._v(" "),a("p",[a("strong",[t._v("音频翻译性能：")]),t._v("  GPT-4o 在语音翻译方面树立了新的最先进水平，并且在 MLS 基准测试中优于 Whisper-v3。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://hlplch.aliyuntm.com/chatgpt/5151.png",alt:""}})]),t._v(" "),a("p",[a("strong",[t._v("M3Exam：")]),t._v("  M3Exam 基准测试既是多语言评估也是视觉评估，由来自其他国家标准化测试的多项选择题组成，有时还包括图形和图表。在所有语言的基准测试中，GPT-4o 都比 GPT-4 更强。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://hlplch.aliyuntm.com/chatgpt/5152.png",alt:""}})]),t._v(" "),a("p",[a("strong",[t._v("视觉理解评估：")]),t._v("  GPT-4o 在视觉感知基准上实现了最先进的性能。所有视觉评估都是 0-shot，其中 MMMU、MathVista 和 ChartQA 作为 0-shot CoT。\n"),a("img",{attrs:{src:"https://hlplch.aliyuntm.com/chatgpt/5153.png",alt:""}})]),t._v(" "),a("h2",{attrs:{id:"可用性"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#可用性"}},[t._v("#")]),t._v(" 可用性")]),t._v(" "),a("p",[t._v("GPT-4o 是chatgpt突破深度学习界限的最新举措，这次是朝着实用性的方向发展。在过去的两年里，chatgpt花费了大量的精力来提高堆栈每一层的效率。作为这项研究的第一个成果，chatgpt能够更广泛地提供 GPT-4 级别模型。 GPT-4o 的功能将迭代推出。")]),t._v(" "),a("p",[t._v("GPT-4o 的文本和图像功能今天开始在 ChatGPT 中推出。chatgpt正在免费套餐中提供 GPT-4o，并向 Plus 用户提供高达 5 倍的消息限制。chatgpt将在未来几周内在 ChatGPT Plus 中推出新版本的语音模式 GPT-4o alpha。")]),t._v(" "),a("p",[t._v("开发人员现在还可以在 API 中访问 GPT-4o 作为文本和视觉模型。与 GPT-4 Turbo 相比，GPT-4o 速度提高 2 倍，价格降低一半，速率限制提高 5 倍。chatgpt计划在未来几周内在 API 中向一小部分值得信赖的合作伙伴推出对 GPT-4o 新音频和视频功能的支持。")]),t._v(" "),a("h2",{attrs:{id:"chatgpt免费用户-可以访问的功能"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#chatgpt免费用户-可以访问的功能"}},[t._v("#")]),t._v(" ChatGPT免费用户，可以访问的功能")]),t._v(" "),a("p",[t._v("chatgpt官博还介绍了，ChatGPT免费用户可以访问新模型加持下的功能，包括：")]),t._v(" "),a("ul",[a("li",[t._v("体验GPT-4级别的智能")]),t._v(" "),a("li",[t._v("从联网后的模型得到响应")]),t._v(" "),a("li",[t._v("分析数据并创建图表")]),t._v(" "),a("li",[t._v("畅聊你拍的照片")]),t._v(" "),a("li",[t._v("上传文件以帮助总结、撰写或分析")]),t._v(" "),a("li",[t._v("发现和使用GPTs和GPT Store")]),t._v(" "),a("li",[t._v("用记忆构建更有用的体验")])]),t._v(" "),a("h2",{attrs:{id:"免费向所有人提供gpt-4级别的ai"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#免费向所有人提供gpt-4级别的ai"}},[t._v("#")]),t._v(" 免费向所有人提供GPT-4级别的AI")]),t._v(" "),a("p",[t._v("这款全新的AI模型，免费向所有人提供GPT-4级别的AI。")]),t._v(" "),a("p",[t._v("现在，进入ChatGPT页面，Plus用户可以抢先体验「最新、最先进的模型」GPT-4o。\n"),a("img",{attrs:{src:"https://hlplch.aliyuntm.com/chatgpt/5154.png",alt:""}}),t._v(" "),a("img",{attrs:{src:"https://hlplch.aliyuntm.com/chatgpt/5155.png",alt:""}})]),t._v(" "),a("p",[t._v("这个带着光环登场的模型，其最大意义就在于，把GPT-4级别的智能，带给了chatgpt的每一位用户！")]),t._v(" "),a("p",[a("strong",[t._v("从此以后，无论你是付费用户，还是免费用户，都能通过它体验GPT-4了。")])]),t._v(" "),a("p",[t._v("唯一不同的是，ChatGPT Plus的消息限制是免费用户的5倍。")]),t._v(" "),a("p",[t._v("并且，GPT-4o不仅提供与GPT-4同等程度的模型能力，推理速度还更快，还能提供同时理解文本、图像、音频等内容的多模态能力。")]),t._v(" "),a("h2",{attrs:{id:"wildcard不开卡gpt4随心用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#wildcard不开卡gpt4随心用"}},[t._v("#")]),t._v(" WildCard不开卡GPT4随心用")]),t._v(" "),a("p",[t._v("如果想成为GPT-4o付费用户点击: "),a("a",{attrs:{href:"https://2233.ai/i/GPT310",target:"_blank",rel:"noopener noreferrer"}},[t._v("WildCard不开卡GPT4随心用"),a("OutboundLink")],1),t._v("  邀请码 "),a("strong",[t._v("GPT310")]),t._v("，直接免 2 美元的开卡费，虚拟卡开好之后，用支付宝充值进行ChatGpt升级，或者不开卡，直接使用chatgpt"),a("a",{attrs:{href:"https://2233.ai/i/GPT310",target:"_blank",rel:"noopener noreferrer"}},[t._v("随心用"),a("OutboundLink")],1),t._v("，只需手机号注册就能使用，等其他海外订阅服务。")]),t._v(" "),a("p",[t._v("在GPT-4o发布之前，通过语音模式（Voice Mode）与ChatGPT对话，平均延迟为2.8秒（GPT-3.5）和5.4秒（GPT-4）。")]),t._v(" "),a("p",[t._v("它可以跨越语音、文本、视觉多种形式，直接进行推理！")]),t._v(" "),a("p",[t._v("GPT-4o是chatgpt首个端到端训练的跨越文本、视觉和音频的新模型，意味着所有输入和输出都由相同的神经网络处理。")]),t._v(" "),a("p",[t._v("这就会彻底颠覆ChatGPT 1亿用户的工作和生活。")]),t._v(" "),a("p",[t._v("不仅如此，由于GPT-4o是「原生的多模态」，自然地集成了语言、视觉和音频等多种能力。")]),t._v(" "),a("p",[t._v("用户可以上传各种图片、视频，以及包含图片和文字的文档，讨论其中的内容。")]),t._v(" "),a("p",[t._v("以上就是这次chatgpt春季发布会的全部内容了。")]),t._v(" "),a("p",[t._v('在这场发布会之前，无数人曾在猜测，chatgpt到底会发一些什么王炸，什么才能配得上奥特曼口中的"magic"。')]),t._v(" "),a("p",[a("img",{attrs:{src:"https://hlplch.aliyuntm.com/chatgpt/5157.png",alt:""}})]),t._v(" "),a("p",[t._v("那现在，chatgpt做到了，他们用GPT-4o依然证明了，他们是AI届的王者。")]),t._v(" "),a("p",[a("strong",[t._v("参考")]),t._v("：\n"),a("a",{attrs:{href:"https://chatgpt.com/index/hello-gpt-4o/",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://chatgpt.com/index/hello-gpt-4o/"),a("OutboundLink")],1)])])}),[],!1,null,null,null);a.default=v.exports}}]);